{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc9f586d-9911-4b69-809f-c20489319984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/swj/VD/src\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "import pickle\n",
    "import numpy as np\n",
    "from src.DataLoader import LoadPickleData\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(os.getcwd())\n",
    "def get_top_k_metric(k, y_predict, test_set_y):\n",
    "        precision, recall = 0, 0\n",
    "        tp, fp, fn = 0, 0, 0\n",
    "        pt_pair = []\n",
    "        for x, y in zip(y_predict, test_set_y):\n",
    "            pt_pair.append([x, y])\n",
    "            \n",
    "        pt_pair.sort(key=lambda x: x[0], reverse=True)\n",
    "        \n",
    "        n_rel = sum((true_r == 1) for (_, true_r) in pt_pair)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est == 1) for (est, _) in pt_pair[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r == 1) and (est == 1))\n",
    "                              for (est, true_r) in pt_pair[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. We here set it to 0.\n",
    "\n",
    "        precision = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. We here set it to 0.\n",
    "\n",
    "        recall = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "        \n",
    "        return n_rel_and_rec_k, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10567776-c20e-45e0-a62a-ae63817abf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      "(4060, 128) (1741, 128) (4060,) (1741,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done 8000 out of 8000 | elapsed:    6.5s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "predicting on the test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 1784 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 2434 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=8)]: Done 3184 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=8)]: Done 4034 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=8)]: Done 4984 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=8)]: Done 6034 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=8)]: Done 7184 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=8)]: Done 8000 out of 8000 | elapsed:    6.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=8)]: Done 1784 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=8)]: Done 2434 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=8)]: Done 3184 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=8)]: Done 4034 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=8)]: Done 4984 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=8)]: Done 6034 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=8)]: Done 7184 tasks      | elapsed:    6.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nums of vul, precision and recall at 10 is 8, 0.8 and 0.09876543209876543\n",
      "nums of vul, precision and recall at 20 is 18, 0.9 and 0.2222222222222222\n",
      "nums of vul, precision and recall at 30 is 27, 0.9 and 0.3333333333333333\n",
      "nums of vul, precision and recall at 40 is 37, 0.925 and 0.4567901234567901\n",
      "nums of vul, precision and recall at 50 is 46, 0.92 and 0.5679012345679012\n",
      "nums of vul, precision and recall at 100 is 72, 0.935064935064935 and 0.8888888888888888\n",
      "nums of vul, precision and recall at 150 is 72, 0.935064935064935 and 0.8888888888888888\n",
      "nums of vul, precision and recall at 200 is 72, 0.935064935064935 and 0.8888888888888888\n",
      "accuracy = 99.19586444572084\n",
      "[[1655    5]\n",
      " [   9   72]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Non-defective       0.99      1.00      1.00      1660\n",
      "    Defective       0.94      0.89      0.91        81\n",
      "\n",
      "     accuracy                           0.99      1741\n",
      "    macro avg       0.96      0.94      0.95      1741\n",
      " weighted avg       0.99      0.99      0.99      1741\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 8000 out of 8000 | elapsed:    6.9s finished\n"
     ]
    }
   ],
   "source": [
    "#In domain\n",
    "repre = LoadPickleData('/home/swj/VD/Representation/PLSTM/FFmpeg_Vul.pkl')\n",
    "non_repre = LoadPickleData('/home/swj/VD/Representation/PLSTM/FFmpeg_NonVul.pkl')\n",
    "\n",
    "n, m = len(repre), len(non_repre)\n",
    "n_features = 128\n",
    "train_set_x = []\n",
    "for x in repre:\n",
    "    train_set_x.append(x)\n",
    "for x in non_repre:\n",
    "    train_set_x.append(x)\n",
    "X = np.asarray(train_set_x)\n",
    "y = np.asarray([1] * n + [0] * m)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=321)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "n_vul = sum((y == 1) for y in y_test)\n",
    "print(n_vul)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "clf = RandomForestClassifier(bootstrap=True, class_weight='balanced', #class_weight={0:1, 1:4},\n",
    "            criterion='entropy', max_depth=40, max_features='auto',\n",
    "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "            min_impurity_split=None, min_samples_leaf=3,\n",
    "            min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=8000, oob_score=False, random_state=None,\n",
    "            verbose=1, warm_start=False, n_jobs=-1)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "# print(\"feature importance:\")\n",
    "# print(clf.feature_importances_)\n",
    "# print (\"\\n\")\n",
    "\n",
    "print (\"\\r\\n\")\n",
    "    \n",
    "    #evaluate the model on the test set\n",
    "print(\"predicting on the test set\")\n",
    "y_predict = clf.predict(X_test)\n",
    "    \n",
    "y_predict_proba = clf.predict_proba(X_test)\n",
    "# print(y_test)\n",
    "# print(y_predict, y_predict_proba)\n",
    "k_list = [10, 20, 30, 40, 50, 100, 150, 200]\n",
    "for k in k_list:\n",
    "    n_vul, precision, recall = get_top_k_metric(k, y_predict, y_test)\n",
    "    print('nums of vul, precision and recall at {0} is {1}, {2} and {3}'.format(k, n_vul, precision, recall))\n",
    "\n",
    "    # Accuracy\n",
    "accuracy = np.mean(y_test==y_predict)*100\n",
    "print (\"accuracy = \" +  str(accuracy))\n",
    "        \n",
    "target_names = [\"Non-defective\",\"Defective\"] #non-buggy->0, buggy->1\n",
    "print (confusion_matrix(y_test, y_predict, labels=[0,1]))   \n",
    "print (\"\\r\\n\")\n",
    "print (\"\\r\\n\")\n",
    "print (classification_report(y_test, y_predict, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7951af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross domain\n",
    "train_set_vul, train_set_nonvul = [], []\n",
    "train_set_vul_path = 'Representation/Train_set1/Vul/'\n",
    "train_set_nonvul_path = 'Representation/Train_set1/NonVul/'\n",
    "\n",
    "test_set_vul, test_set_nonvul = [], []\n",
    "test_set_vul_path = 'Representation/Test_set1/Vul/'\n",
    "test_set_nonvul_path = 'Representation/Test_set1/NonVul/'\n",
    "\n",
    "files = os.listdir(train_set_vul_path)\n",
    "for file in files:\n",
    "    _, ext = os.path.splitext(file)\n",
    "    _, filename = os.path.split(file)\n",
    "    if ext == '.pkl':\n",
    "        full_path = ''\n",
    "        train_set_vul.append(LoadPickleData(train_set_vul_path + filename))\n",
    "        \n",
    "files = os.listdir(train_set_nonvul_path)\n",
    "for file in files:\n",
    "    _, ext = os.path.splitext(file)\n",
    "    _, filename = os.path.split(file)\n",
    "    if ext == '.pkl':\n",
    "        full_path = ''\n",
    "        train_set_nonvul.append(LoadPickleData(train_set_nonvul_path + filename))\n",
    "        \n",
    "files = os.listdir(test_set_vul_path)\n",
    "for file in files:\n",
    "    _, ext = os.path.splitext(file)\n",
    "    _, filename = os.path.split(file)\n",
    "    if ext == '.pkl':\n",
    "        full_path = ''\n",
    "        test_set_vul.append(LoadPickleData(test_set_vul_path + filename))\n",
    "        \n",
    "files = os.listdir(test_set_nonvul_path)\n",
    "for file in files:\n",
    "    _, ext = os.path.splitext(file)\n",
    "    _, filename = os.path.split(file)\n",
    "    if ext == '.pkl':\n",
    "        full_path = ''\n",
    "        test_set_nonvul.append(LoadPickleData(test_set_nonvul_path + filename))\n",
    "        \n",
    "train_set_x = []\n",
    "num_vul, num_nonvul = 0, 0\n",
    "for vul in train_set_vul:\n",
    "    for x in vul:\n",
    "        train_set_x.append(x)\n",
    "        num_vul += 1\n",
    "for nonvul in train_set_nonvul:\n",
    "    for x in nonvul:\n",
    "        train_set_x.append(x)\n",
    "        num_nonvul += 1\n",
    "X_train = np.asarray(train_set_x)\n",
    "y_train = np.asarray([1] * num_vul + [0] * num_nonvul)\n",
    "print('train_set:')\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "test_set_x = []\n",
    "num_vul, num_nonvul = 0, 0\n",
    "for vul in test_set_vul:\n",
    "    for x in vul:\n",
    "        test_set_x.append(x)\n",
    "        num_vul += 1\n",
    "for nonvul in test_set_nonvul:\n",
    "    for x in nonvul:\n",
    "        test_set_x.append(x)\n",
    "        num_nonvul += 1\n",
    "X_test = np.asarray(test_set_x)\n",
    "y_test = np.asarray([1] * num_vul + [0] * num_nonvul)\n",
    "print('test_set:')\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "\n",
    "n_vul = sum((y == 1) for y in y_test)\n",
    "print(n_vul)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "clf = RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
    "            criterion='entropy', max_depth=30, max_features='auto',\n",
    "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "            min_impurity_split=None, min_samples_leaf=3,\n",
    "            min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=8000, oob_score=False, random_state=None,\n",
    "            verbose=1, warm_start=False, n_jobs=-1)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "print (\"\\r\\n\")\n",
    "    \n",
    "#evaluate the model on the test set\n",
    "print(\"predicting on the test set\")\n",
    "y_predict = clf.predict(X_test)\n",
    "    \n",
    "y_predict_proba = clf.predict_proba(X_test)\n",
    "k_list = [10, 20, 30, 40, 50, 100, 150, 200]\n",
    "for k in k_list:\n",
    "    n_vul, precision, recall = get_top_k_metric(k, y_predict, y_test)\n",
    "    print('nums of vul, precision and recall at {0} is {1}, {2} and {3}'.format(k, n_vul, precision, recall))\n",
    "\n",
    "# Accuracy\n",
    "accuracy = np.mean(y_test==y_predict)*100\n",
    "print (\"accuracy = \" +  str(accuracy))\n",
    "        \n",
    "target_names = [\"Non-defective\",\"Defective\"] #non-buggy->0, buggy->1\n",
    "print (confusion_matrix(y_test, y_predict, labels=[0,1]))   \n",
    "print (\"\\r\\n\")\n",
    "print (\"\\r\\n\")\n",
    "print (classification_report(y_test, y_predict, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
