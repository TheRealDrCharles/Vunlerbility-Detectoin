{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ebfea3-d8c3-4911-8add-2886678bece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.includes import *\n",
    "\n",
    "import nltk\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import os.path\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "home_path = '/home/swj/VD/'\n",
    "embedding_path = home_path + 'embedding/'\n",
    "\n",
    "all_words = []\n",
    "    \n",
    "mode = \"withString\" #default\n",
    "\n",
    "    \n",
    "\n",
    "# Loading the training corpus\n",
    "print(\"Loading \" + mode)  \n",
    "with open(embedding_path + 'pythontraining' + '_'+mode+\"_X\", 'r') as file:\n",
    "    pythondata = file.read().lower().replace('\\n', ' ')\n",
    "\n",
    "print(\"Length of the training file: \" + str(len(pythondata)) + \".\")\n",
    "print(\"It contains \" + str(pythondata.count(\" \")) + \" individual code tokens.\")\n",
    "\n",
    "# Preparing the dataset (or loading already processed dataset to not do everything again)\n",
    "if (os.path.isfile(embedding_path + 'pythontraining_processed_' + mode)):\n",
    "    with open (embedding_path + 'pythontraining_processed_' + mode, 'rb') as fp:\n",
    "        all_words = pickle.load(fp)\n",
    "    print(\"loaded processed model.\")\n",
    "else:  \n",
    "    print(\"now processing...\")\n",
    "    processed = pythondata\n",
    "    all_sentences = nltk.sent_tokenize(processed)\n",
    "    all_words = [nltk.word_tokenize(sent) for sent in all_sentences]\n",
    "    print(\"saving\")\n",
    "    with open(embedding_path + 'pythontraining_processed_' + mode, 'wb') as fp:\n",
    "        pickle.dump(all_words, fp)\n",
    "\n",
    "print(\"processed.\\n\")\n",
    "\n",
    "mincount, iterationen, s = 10, 300, 200\n",
    "print(111)\n",
    "fname = embedding_path + \"word2vec_\"+mode+str(mincount) + \"-\" + str(iterationen) +\"-\" + str(s)+ \".model\"\n",
    "\n",
    "if (os.path.isfile(fname)):\n",
    "    print(\"model already exists.\")\n",
    "\n",
    "else:\n",
    "    print(\"calculating model...\")\n",
    "    # training the model\n",
    "    model = Word2Vec(all_words, vector_size=s, min_count=mincount, epochs=iterationen, workers = 4)  \n",
    "    vocabulary = model.wv.vocab\n",
    "    model.save(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263d632e-c05c-402f-8a8f-863e80d06427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.includes import *\n",
    "\n",
    "model_name = 'bplstm'\n",
    "home_path = '/home/swj/VD/'\n",
    "code_type = 'python'\n",
    "embedding_path = home_path + 'embedding/'\n",
    "mode = \"command_injection\"\n",
    "model_path = home_path + 'trained_model/' + code_type + '_' + mode + '/'\n",
    "\n",
    "#default mode / type of vulnerability\n",
    "data_path = home_path + 'data/python_data_set/' + mode + '/'\n",
    "### hyperparameters for the w2v model\n",
    "mincount = 10 #minimum times a word has to appear in the corpus to be in the word2vec model\n",
    "iterationen = 300 #training iterations for the word2vec model\n",
    "s = 200 #dimensions of the word2vec model\n",
    "w = \"withString\" #word2vec model is not replacing strings but keeping them\n",
    "### paramters for the filtering and creation of samples\n",
    "restriction = [20000,5,6,10] #which samples to filter out\n",
    "step = 5 #step lenght n in the description\n",
    "fulllength = 200 #context length m in the description\n",
    "mode2 = str(step)+\"_\"+str(fulllength) \n",
    "\n",
    "w2v = embedding_path + \"word2vec_\"+w+str(mincount) + \"-\" + str(iterationen) +\"-\" + str(s)\n",
    "w2vmodel = w2v + \".model\"\n",
    "#load word2vec model\n",
    "if not (os.path.isfile(w2vmodel)):\n",
    "    print(\"word2vec model is still being created...\")\n",
    "    sys.exit()\n",
    "w2v_model = Word2Vec.load(w2vmodel)\n",
    "print('word2vec model loaded!')\n",
    "word_vectors = w2v_model.wv\n",
    "words = list(w2v_model.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05787cf-bf5e-43ff-86bf-54e19acf24b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(word_vectors), len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca828e32-212f-40f0-8e89-f8d4cc32e8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(words)):\n",
    "    print(words[i],  word_vectors[words[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62b7d957-e49d-487d-b6ed-c523ea52465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\" Module for gathering disk information ''' import logging import salt.utils log=logging.getLogger(__name__) def __virtual__(): ''' Only work on POSIX-like systems ''' if salt.utils.is_windows(): return False\", 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "652e4346-8529-4a39-a68b-e36dad21af3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'Module', 'for', 'gathering', 'disk', 'information', \"'''\", 'import', 'logging', 'import', 'salt.utils', 'log=logging.getLogger(__name__)', 'def', '__virtual__():', \"'''\", 'Only', 'work', 'on', 'POSIX-like', 'systems', \"'''\", 'if', 'salt.utils.is_windows():', 'return', 'False']\n"
     ]
    }
   ],
   "source": [
    "a = list(a[0].split(' '))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9990c6f7-3287-4b8f-a5c1-b691df532a96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
