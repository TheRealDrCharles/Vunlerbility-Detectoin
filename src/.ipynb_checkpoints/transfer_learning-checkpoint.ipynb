{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3400c147-b875-4f2c-8d65-131573c823d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing VLC\n",
      "#0: 1.0 0.5 0.6666666666666666 0.9967532467532467\n",
      "#1: 0.5 0.36363636363636365 0.4210526315789474 0.9940476190476191\n",
      "#2: 0.9090909090909091 0.5882352941176471 0.7142857142857143 0.9956709956709957\n",
      "#3: 1.0 0.4 0.5714285714285715 0.9951298701298701\n",
      "#4: 1.0 0.5454545454545454 0.7058823529411764 0.9972943722943723\n",
      "#5: 1.0 0.5 0.6666666666666666 0.9978354978354979\n",
      "#6: 0.9 0.5294117647058824 0.6666666666666667 0.9951298701298701\n",
      "#7: 0.6666666666666666 0.15384615384615385 0.25 0.9935064935064936\n",
      "#8: 0.8888888888888888 0.6153846153846154 0.7272727272727274 0.9967532467532467\n",
      "#9: 0.8888888888888888 0.8 0.8421052631578948 0.9983766233766234\n",
      "#10: 1.0 0.125 0.2222222222222222 0.9962121212121212\n",
      "#11: 0.75 0.5454545454545454 0.631578947368421 0.9962121212121212\n",
      "#12: 0.8333333333333334 0.5555555555555556 0.6666666666666667 0.9972943722943723\n",
      "#13: 0.8181818181818182 0.6428571428571429 0.7200000000000001 0.9962121212121212\n",
      "#14: 0.8571428571428571 0.5454545454545454 0.6666666666666665 0.9967532467532467\n",
      "#15: 0.8888888888888888 0.6153846153846154 0.7272727272727274 0.9967532467532467\n",
      "#16: 1.0 0.6363636363636364 0.7777777777777778 0.9978354978354979\n",
      "#17: 1.0 0.46153846153846156 0.631578947368421 0.9962121212121212\n",
      "#18: 1.0 0.42857142857142855 0.6 0.9935064935064936\n",
      "#19: 0.8 0.25 0.38095238095238093 0.9929653679653679\n",
      "#20: 1.0 0.6875 0.8148148148148148 0.9972943722943723\n",
      "#21: 0.875 0.7 0.7777777777777777 0.9978354978354979\n",
      "#22: 1.0 0.6 0.7499999999999999 0.9978354978354979\n",
      "#23: 1.0 0.5454545454545454 0.7058823529411764 0.9972943722943723\n",
      "#24: 1.0 0.6 0.7499999999999999 0.9967532467532467\n",
      "#25: 1.0 0.46153846153846156 0.631578947368421 0.9962121212121212\n",
      "#26: 0.9166666666666666 0.6111111111111112 0.7333333333333334 0.9956709956709957\n",
      "#27: 0.6666666666666666 0.5 0.5714285714285715 0.9967532467532467\n",
      "#28: 0.8888888888888888 0.36363636363636365 0.5161290322580644 0.9918831168831169\n",
      "#29: 0.8571428571428571 0.6 0.7058823529411764 0.9972943722943723\n"
     ]
    }
   ],
   "source": [
    "#30 times tests in domain\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "from src.includes import *\n",
    "\n",
    "model_name = 'blstm'\n",
    "data_set_name = 'VLC'\n",
    "home_path = '/home/swj/VD/'\n",
    "ways = 'AST'\n",
    "classifier = 'RF'\n",
    "code_type = 'C++'\n",
    "#change this floder\n",
    "path = home_path + 'Representation/' + model_name + '_' + ways + '/' + code_type + '/'\n",
    "save_path = home_path + 'src/' + model_name + '_' + ways + '/' + code_type + '/'\n",
    "model_path = home_path + 'trained_model' + '/' + model_name + '_' + data_set_name + '_'  + ways + '_' + 'RF' + '.joblib'\n",
    "#if not os.path.exists(model_path): os.makedirs(model_path)\n",
    "files= os.listdir(path)\n",
    "for file in files:\n",
    "    if not os.path.isdir(file):\n",
    "        data_set_name = file\n",
    "        if data_set_name != 'VLC': continue\n",
    "        res = list()\n",
    "        path2 = path + data_set_name + '/'\n",
    "        files2 = os.listdir(path2)\n",
    "        non_repre, repre = None, None\n",
    "        for file2 in files2:\n",
    "            if not os.path.isdir(file2):\n",
    "                if file2 == 'NonVul.pkl':\n",
    "                    non_repre = LoadPickleData(path + data_set_name + '/' + file2)\n",
    "                if file2 == 'Vul.pkl':\n",
    "                    repre = LoadPickleData(path + data_set_name + '/' + file2)\n",
    "        #print(non_repre is None, repre is None)\n",
    "        if repre is None and non_repre is None:\n",
    "            print('No repres yet!')\n",
    "            continue\n",
    "        else:\n",
    "            print(f'testing {data_set_name}')\n",
    "        #writer = SummaryWriter(comment=model_name + data_set_name + classifier)\n",
    "        f1max = 0\n",
    "        for i in range(30):\n",
    "            n, m = len(repre), len(non_repre)\n",
    "            n_features = 128\n",
    "            train_set_x = []\n",
    "            for x in repre:\n",
    "                train_set_x.append(x)\n",
    "            for x in non_repre:\n",
    "                train_set_x.append(x)\n",
    "            X = np.asarray(train_set_x)\n",
    "            y = np.asarray([1] * n + [0] * m)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "            n_vul = sum((y == 1) for y in y_test)\n",
    "            clf = None\n",
    "            if classifier == 'SVM':\n",
    "                clf = SVC()\n",
    "            elif classifier == 'MLP':\n",
    "                clf = MLPClassifier(hidden_layer_sizes=200, random_state=None, max_iter=300)\n",
    "            elif classifier == 'RF':\n",
    "                clf = RandomForestClassifier(bootstrap=True, class_weight='balanced', #class_weight={0:1, 1:4},\n",
    "                            criterion='entropy', max_depth=40, max_features='auto',\n",
    "                            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                            min_impurity_split=None, min_samples_leaf=3,\n",
    "                            min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
    "                            n_estimators=8000, oob_score=False, random_state=None,\n",
    "                            verbose=0, warm_start=False, n_jobs=-1)\n",
    "            \n",
    "            clf = clf.fit(X_train, y_train)\n",
    "            y_predict = clf.predict(X_test)\n",
    "            #writer.add_pr_curve('pr_curve', y_test, y_predict, i)\n",
    "            target_names = [\"Non-defective\",\"Defective\"] #non-buggy->0, buggy->1\n",
    "            ans = classification_report(y_test, y_predict, target_names=target_names, output_dict=True)\n",
    "            print('#' + str(i) + ':', ans['Defective']['precision'], ans['Defective']['recall'], ans['Defective']['f1-score'], ans['accuracy'])\n",
    "            if f1max < ans['Defective']['f1-score']:\n",
    "                f1max = ans['Defective']['f1-score']\n",
    "                joblib.dump(clf, model_path)\n",
    "            res.append(['#' + str(i) + ':', ans['Defective']['precision'], ans['Defective']['recall'], ans['Defective']['f1-score'], ans['accuracy']])\n",
    "        res = np.array(res)\n",
    "        res = res[:, 1:6]\n",
    "        df = pd.DataFrame(res, columns=['precision', 'recall', 'f1-score', 'accuracy'])\n",
    "        \n",
    "        if not os.path.exists(save_path): os.makedirs(save_path)\n",
    "        #change this also according above\n",
    "        df.to_csv(save_path + data_set_name + '_' +  ways + '.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd44224a-36ae-4d10-819f-f6544c6e6b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the boxx\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "#change this \n",
    "#path = '/home/swj/VD/src/BLSTM_org/'\n",
    "path = save_path = home_path + 'src/' + model_name + '_' + ways + '/'\n",
    "files= os.listdir(path)\n",
    "\n",
    "res_data = []\n",
    "for file in files:\n",
    "    if not os.path.isdir(file):\n",
    "        filename, ext = file.split('.')\n",
    "        if ext == 'csv' and filename != 'res':\n",
    "            \n",
    "            res = pd.read_csv(path + file)\n",
    "            fig,axes = plt.subplots(2, 2)\n",
    "            plt.subplots_adjust(wspace=0.5,hspace=0.5)\n",
    "            res['precision'].plot(kind='box',ax=axes[0][0])\n",
    "            res['recall'].plot(kind='box',ax=axes[0][1])\n",
    "            res['f1-score'].plot(kind='box',ax=axes[1][0])\n",
    "            res['accuracy'].plot(kind='box',ax=axes[1][1])\n",
    "            fig.savefig(path + filename + '.png')\n",
    "            \n",
    "            res = np.array(res)\n",
    "            print(res)\n",
    "            precision = np.median(res[:, 1])\n",
    "            recall = np.median(res[:, 2])\n",
    "            f1_score = np.median(res[:, 3])\n",
    "            accuracy = np.median(res[:, 4])\n",
    "            print('their are', precision, recall, f1_score, accuracy)\n",
    "            p_iqr = np.quantile(res[:, 1] ,0.75,interpolation='higher') - np.quantile(res[:, 1] ,0.25,interpolation='lower')\n",
    "            r_iqr = np.quantile(res[:, 2] ,0.75,interpolation='higher') - np.quantile(res[:, 2] ,0.25,interpolation='lower')\n",
    "            f_iqr = np.quantile(res[:, 3] ,0.75,interpolation='higher') - np.quantile(res[:, 3] ,0.25,interpolation='lower')\n",
    "            a_iqr = np.quantile(res[:, 4] ,0.75,interpolation='higher') - np.quantile(res[:, 4] ,0.25,interpolation='lower')\n",
    "            res_data.append([filename, precision, p_iqr, recall, r_iqr, f1_score, f_iqr, accuracy, a_iqr])\n",
    "\n",
    "res_data = np.array(res_data)\n",
    "\n",
    "df = pd.DataFrame(res_data, columns=['data_set', 'precision', 'p_iqr', 'recall', 'r_iqr', 'f1-score', 'f_iqr', 'accuracy', 'a_iqr'])\n",
    "df.to_csv(path + 'res.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008b0cbe-09a4-4b98-a9f9-df33dbf95751",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross domain setting\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "from src.includes import *\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "home_path = '/home/swj/VD/'\n",
    "model_name = 'bplstm'\n",
    "ways = 'ast'\n",
    "classifier = 'RF'\n",
    "\n",
    "source_domian_data_set_name = 'LibPNG'\n",
    "target_domain_data_set_name = 'LibTIFF'\n",
    "\n",
    "source_domain_data_set_vul = torch.from_numpy(LoadPickleData(home_path + 'Representation/' + model_name + '_' + ways + '/' + source_domian_data_set_name + '/' + 'Vul.pkl')).to(device)\n",
    "source_domain_data_set_nonvul = torch.from_numpy(LoadPickleData(home_path + 'Representation/' + model_name + '_' + ways + '/' + source_domian_data_set_name + '/' + 'NonVul.pkl')).to(device)\n",
    "target_domain_data_set_vul = torch.from_numpy(LoadPickleData(home_path + 'Representation/' + model_name + '_' + ways + '/' + target_domain_data_set_name + '/' + 'Vul.pkl')).to(device)\n",
    "target_domain_data_set_nonvul = torch.from_numpy(LoadPickleData(home_path + 'Representation/' + model_name + '_' + ways + '/' + target_domain_data_set_name + '/' + 'NonVul.pkl')).to(device)\n",
    "\n",
    "\n",
    "dim1 = [source_domain_data_set_vul.shape[0], source_domain_data_set_nonvul.shape[0], target_domain_data_set_vul.shape[0], target_domain_data_set_nonvul.shape[0]]\n",
    "dim2 = [source_domain_data_set_vul.shape[1], source_domain_data_set_nonvul.shape[1], target_domain_data_set_vul.shape[1], target_domain_data_set_nonvul.shape[1]]\n",
    "source_domain_vul_pos, source_domain_nonvul_pos, target_domain_vul_pos, target_domain_nonvul_pos = \\\n",
    "sum(dim1[:1]), sum(dim1[:2]), sum(dim1[:3]), sum(dim1[:4])\n",
    "\n",
    "print(source_domain_vul_pos, source_domain_nonvul_pos, target_domain_vul_pos, target_domain_nonvul_pos)\n",
    "X = torch.cat((source_domain_data_set_vul, source_domain_data_set_nonvul, target_domain_data_set_vul, target_domain_data_set_nonvul), dim = 0)\n",
    "print(X.shape)\n",
    "#print(X)\n",
    "domain_set = [1] * sum(dim1[:2]) + [0] * sum(dim1[2:4])\n",
    "A = Newton(X, domain_set, 4)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60abc4ee-7017-46c0-b1e7-505a0efc2656",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross domain setting\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "from src.includes import *\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "home_path = '/home/swj/VD/'\n",
    "model_name = 'bplstm'\n",
    "ways = 'ast'\n",
    "classifier = 'RF'\n",
    "\n",
    "source_domian_data_set_name = 'FFmpeg'\n",
    "target_domain_data_set_name = 'LibTIFF'\n",
    "\n",
    "source_domain_data_set_vul = torch.from_numpy(LoadPickleData(home_path + 'Representation/' + model_name + '_' + ways + '/' + source_domian_data_set_name + '/' + 'Vul.pkl')).to(device)\n",
    "source_domain_data_set_nonvul = torch.from_numpy(LoadPickleData(home_path + 'Representation/' + model_name + '_' + ways + '/' + source_domian_data_set_name + '/' + 'NonVul.pkl')).to(device)\n",
    "target_domain_data_set_vul = torch.from_numpy(LoadPickleData(home_path + 'Representation/' + model_name + '_' + ways + '/' + target_domain_data_set_name + '/' + 'Vul.pkl')).to(device)\n",
    "target_domain_data_set_nonvul = torch.from_numpy(LoadPickleData(home_path + 'Representation/' + model_name + '_' + ways + '/' + target_domain_data_set_name + '/' + 'NonVul.pkl')).to(device)\n",
    "\n",
    "\n",
    "dim1 = [source_domain_data_set_vul.shape[0], source_domain_data_set_nonvul.shape[0], target_domain_data_set_vul.shape[0], target_domain_data_set_nonvul.shape[0]]\n",
    "dim2 = [source_domain_data_set_vul.shape[1], source_domain_data_set_nonvul.shape[1], target_domain_data_set_vul.shape[1], target_domain_data_set_nonvul.shape[1]]\n",
    "source_domain_vul_pos, source_domain_nonvul_pos, target_domain_vul_pos, target_domain_nonvul_pos = \\\n",
    "sum(dim1[:1]), sum(dim1[:2]), sum(dim1[:3]), sum(dim1[:4])\n",
    "\n",
    "print(source_domain_vul_pos, source_domain_nonvul_pos, target_domain_vul_pos, target_domain_nonvul_pos)\n",
    "X = torch.cat((source_domain_data_set_vul, source_domain_data_set_nonvul, target_domain_data_set_vul, target_domain_data_set_nonvul), dim = 0)\n",
    "#print(X)\n",
    "domain_set = [1] * sum(dim1[:2]) + [0] * sum(dim1[2:4])\n",
    "A2 = Newton(X, domain_set, 4)\n",
    "print(A2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea92bd65-8b4d-4da9-a18f-61433eb41a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross domain setting\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "from src.includes import *\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "home_path = '/home/swj/VD/'\n",
    "model_name = 'bplstm'\n",
    "ways = 'ast'\n",
    "classifier = 'RF'\n",
    "\n",
    "source_domian_data_set_name = 'Asterisk'\n",
    "target_domain_data_set_name = 'VLC'\n",
    "\n",
    "source_domain_data_set_vul = torch.from_numpy(LoadPickleData(home_path + 'Representation/' + model_name + '_' + ways + '/' + source_domian_data_set_name + '/' + 'Vul.pkl')).to(device)\n",
    "source_domain_data_set_nonvul = torch.from_numpy(LoadPickleData(home_path + 'Representation/' + model_name + '_' + ways + '/' + source_domian_data_set_name + '/' + 'NonVul.pkl')).to(device)\n",
    "target_domain_data_set_vul = torch.from_numpy(LoadPickleData(home_path + 'Representation/' + model_name + '_' + ways + '/' + target_domain_data_set_name + '/' + 'Vul.pkl')).to(device)\n",
    "target_domain_data_set_nonvul = torch.from_numpy(LoadPickleData(home_path + 'Representation/' + model_name + '_' + ways + '/' + target_domain_data_set_name + '/' + 'NonVul.pkl')).to(device)\n",
    "\n",
    "\n",
    "dim1 = [source_domain_data_set_vul.shape[0], source_domain_data_set_nonvul.shape[0], target_domain_data_set_vul.shape[0], target_domain_data_set_nonvul.shape[0]]\n",
    "dim2 = [source_domain_data_set_vul.shape[1], source_domain_data_set_nonvul.shape[1], target_domain_data_set_vul.shape[1], target_domain_data_set_nonvul.shape[1]]\n",
    "source_domain_vul_pos, source_domain_nonvul_pos, target_domain_vul_pos, target_domain_nonvul_pos = \\\n",
    "sum(dim1[:1]), sum(dim1[:2]), sum(dim1[:3]), sum(dim1[:4])\n",
    "\n",
    "print(source_domain_vul_pos, source_domain_nonvul_pos, target_domain_vul_pos, target_domain_nonvul_pos)\n",
    "X = torch.cat((source_domain_data_set_vul, source_domain_data_set_nonvul, target_domain_data_set_vul, target_domain_data_set_nonvul), dim = 0)\n",
    "#print(X)\n",
    "domain_set = [1] * sum(dim1[:2]) + [0] * sum(dim1[2:4])\n",
    "A3 = Newton(X, domain_set, 4)\n",
    "print(A3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
